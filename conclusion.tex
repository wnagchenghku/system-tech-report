\section{Conclusion} \label{sec:conclusion}

\xxx is an RDMA-based \paxos system that can efficiently replicate general 
server programs. Evaluation on five consensus protocols and \nprog widely used 
programs shows that \xxx is fast, scalable, and deployable. Besides, we have 
integrated \xxx into virtual machine to greatly improve the reliability of VM.
In this integration, we proposed \vsmr, a novel \smr approach that makes VM 
fault-tolerance much faster and more scalable on multi-core. We have described 
\yyy, a \vsmr system implementation which leverages \xxx \smr system and 
evaluation of \yyy on a wide range of real-world server programs and services. 
\yyy runs several times faster than two popular primary-backup systems and it 
saves much bandwidth.

Below, we summarize the novelty, practicability, and patent protectability of 
\xxx and \yyy respectively.

\noindent
\textbf{Novelty.}

\begin{itemize}
\item \xxx's runtime system uses \emph{fast} RDMA primitives to 
invoke consensus processes on requests \emph{concurrently} 
(\S\ref{sec:concurrent}). Besides, it addresses several practical issues 
including \emph{atomic} delivery of RDMA messages (\S\ref{sec:atomic}) and  
\emph{transparent} replication. All these features make \xxx a novel RDMA-based 
\paxos protocol.
\item \emph{\vsmr} is a novel \smr approach that makes VM fault-tolerance much 
\emph{faster} and \emph{more scalable} on multi-core. Leveraging the powerful 
fault-tolerance of \paxos, \vsmr tackles the ``split-brain 
problem'' in primary-backup systems. \yyy is a \vsmr system implementation 
which leverages \xxx \paxos system. \yyy develops several optimizations for 
improving the performance, including including efficient determination of slot 
boundary and concurrent computation of dirty page hashes, which also make \yyy a 
novel VM fault tolerance system.
\end{itemize}

\noindent
\textbf{Practicability.}

\begin{itemize}
\item Our initial results show that \xxx can provide fault 
tolerance to server programs with low performance overhead without requiring 
server developers' intervention (\S\ref{sec:evaluation}). Compared with \nprog 
server programs' unreplicated executions, \xxx incurred \latencyoverhead 
overhead in response time and \tputoverhead in throughput. Its consensus 
latency outperformed four traditional consensus protocols by at least 
\comptradlow and faster than a recent RDMA-based consensus protocol \dare by 
\fasterDARE in average. This consensus latency stayed almost constant to the 
number of replicas and concurrent requests.
\item On average, \yyy's throughput is \avgtput higher than two popular VM 
fault-tolerance systems, \qemumc and \colo, on 4-vCPU VMs, \avgsixteen higher 
on 16-vCPU VMs. Compared to unreplicated executions, \xxx's overhead on 
response time is modest. \xxx has reasonable CPU usage. Meanwhile, \yyy 
consumes \avgbandwidth less network bandwidth than both \qemumc and \colo on 
average. It enables consolidating multiple fault-tolerant VMs on one host.
\end{itemize}

\noindent
\textbf{Patent Protectability.} \yyy's throughput is \avgtput higher 
than two widely-used VM fault-tolerance systems (\qemumc and \colo) on 4-vCPU 
VMs, \avgsixteen higher on 16-vCPU VMs. At the same time, \yyy consumes 
\avgbandwidth less network bandwidth than both \qemumc and \colo on average. 
Therefore, if a VM fault tolerance technique is as fast and scalable as \yyy and 
consumes as little bandwidth as \yyy, it is nearly impossible for it to achieve 
this without leveraging \yyy's mechanism.
